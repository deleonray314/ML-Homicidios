# ğŸš€ GuÃ­a RÃ¡pida: Ejecutar ETL del Data Lake

## âœ… Pasos Completados

1. âœ… Docker corriendo (Data Lake, Data Warehouse, Adminer)
2. âœ… Esquemas de base de datos creados
3. âœ… CÃ³digo ETL implementado:
   - `src/utils/logger.py` - Logging estructurado
   - `src/data_ingestion/api_client.py` - Cliente de API
   - `src/data_ingestion/db_connection.py` - ConexiÃ³n a PostgreSQL
   - `src/data_ingestion/data_lake_loader.py` - Cargador de datos
   - `scripts/load_datalake.py` - Script principal

## ğŸ”§ Problema Actual

El puerto 5433 no estÃ¡ expuesto. Necesitas reiniciar Docker.

## ğŸ¯ SoluciÃ³n RÃ¡pida

```bash
# 1. Detener Docker
docker-compose down

# 2. Iniciar Docker (con puerto 5433 expuesto)
docker-compose up -d

# 3. Esperar 10 segundos para que inicie

# 4. Probar carga de departamentos
python scripts/load_datalake.py --dataset departamentos
```

## ğŸ“Š Comandos Disponibles

### Carga Inicial Completa
```bash
python scripts/load_datalake.py --initial
```

### Carga Incremental
```bash
python scripts/load_datalake.py --incremental
```

### Cargar Dataset EspecÃ­fico
```bash
# Departamentos (33 registros)
python scripts/load_datalake.py --dataset departamentos

# Municipios (~1100 registros)
python scripts/load_datalake.py --dataset municipios

# Homicidios (todos los registros histÃ³ricos)
python scripts/load_datalake.py --dataset homicidios --initial
```

## ğŸ” Verificar Datos en Adminer

1. Abre: http://localhost:8080
2. Conecta:
   - Sistema: PostgreSQL
   - Servidor: `datalake`
   - Usuario: `datalake_user`
   - ContraseÃ±a: `datalake_password_2024`
   - Base de datos: `homicidios_datalake`
3. Explora las tablas:
   - `raw_homicidios`
   - `raw_divipola_departamentos`
   - `raw_divipola_municipios`
   - `data_load_log`

## âš ï¸ Troubleshooting

**Error: Connection refused**
- SoluciÃ³n: Reinicia Docker con `docker-compose down && docker-compose up -d`

**Error: No module named 'src'**
- SoluciÃ³n: Ejecuta desde la raÃ­z del proyecto, no desde `src/`

**Error: API timeout**
- SoluciÃ³n: Verifica tu conexiÃ³n a internet
- La API de Datos Abiertos puede estar lenta

## ğŸ“ PrÃ³ximos Pasos

DespuÃ©s de cargar los datos:
1. Verificar en Adminer que los datos se cargaron
2. Implementar ETL del Data Warehouse (transformaciÃ³n al modelo estrella)
3. Crear dashboards en Streamlit
