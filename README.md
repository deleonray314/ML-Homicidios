# üîç ML-Homicidios

**Sistema de Machine Learning para Predicci√≥n de Tasas de Homicidios en Colombia**

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-red.svg)](https://streamlit.io/)
[![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)](https://www.docker.com/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

---

## üìã Descripci√≥n

ML-Homicidios es un sistema completo de Machine Learning containerizado que predice tasas de homicidios en Colombia a nivel de:
- üèõÔ∏è **Departamento**
- üèôÔ∏è **Municipio**
- üìç **Zona**
- üèòÔ∏è **Tipo de Municipio**

El sistema integra **tres fuentes de datos oficiales**:
1. **Homicidios**: Datos de homicidios de Datos Abiertos Colombia
2. **DIVIPOLA Departamentos**: Divisi√≥n Pol√≠tico-Administrativa - Departamentos (DANE)
3. **DIVIPOLA Municipios**: Divisi√≥n Pol√≠tico-Administrativa - Municipios (DANE)

Extrae autom√°ticamente datos de la **API de Datos Abiertos de Colombia**, los procesa a trav√©s de un pipeline ETL hacia un Data Lake y Data Warehouse, entrena modelos de ML, y sirve predicciones a trav√©s de un dashboard interactivo de Streamlit.

---

## üéØ Objetivos del Proyecto

1. **Aprendizaje**: Desarrollar habilidades en ingenier√≠a de datos y ML en producci√≥n
2. **Predicci√≥n**: Generar predicciones precisas de tasas de homicidios
3. **Visualizaci√≥n**: Proporcionar insights accionables a trav√©s de dashboards interactivos
### Core
- **Python 3.11+**: Lenguaje principal
- **Docker & Docker Compose**: Containerizaci√≥n
- **Git**: Control de versiones

### Data Pipeline
- **Requests & Sodapy**: Extracci√≥n de datos de APIs
- **Pandas & Polars**: Manipulaci√≥n de datos
- **Parquet**: Almacenamiento eficiente (Data Lake)
- **Python-Crontab**: Automatizaci√≥n de tareas

### Machine Learning
- **Scikit-learn**: Algoritmos base y preprocessing
- **XGBoost & LightGBM**: Gradient boosting
- **Prophet**: Forecasting de series temporales
- **MLflow**: Tracking de experimentos (opcional)

### Visualizaci√≥n
- **Streamlit**: Framework de dashboard
- **Plotly**: Gr√°ficos interactivos
- **Folium & GeoPandas**: Mapas de Colombia

### Testing & Quality
- **Pytest**: Framework de testing
- **Black, Flake8, Isort**: Code quality
- **MyPy**: Type checking

---

## üìÅ Estructura del Proyecto

```
ML-Homicidios/
‚îú‚îÄ‚îÄ üìÇ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/              # Data Lake - Datos crudos
‚îÇ   ‚îú‚îÄ‚îÄ processed/        # Data Warehouse - Datos procesados
‚îÇ   ‚îî‚îÄ‚îÄ models/           # Modelos entrenados
‚îú‚îÄ‚îÄ üìÇ src/
‚îÇ   ‚îú‚îÄ‚îÄ config/           # Configuraci√≥n centralizada
‚îÇ   ‚îú‚îÄ‚îÄ data_ingestion/   # Cliente API y scheduler
‚îÇ   ‚îú‚îÄ‚îÄ etl/              # Pipeline ETL
‚îÇ   ‚îú‚îÄ‚îÄ features/         # Ingenier√≠a de features
‚îÇ   ‚îú‚îÄ‚îÄ models/           # Entrenamiento y predicci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ utils/            # Utilidades y logging
‚îú‚îÄ‚îÄ üìÇ app/
‚îÇ   ‚îú‚îÄ‚îÄ streamlit_app.py  # Dashboard principal
‚îÇ   ‚îú‚îÄ‚îÄ pages/            # P√°ginas del dashboard
‚îÇ   ‚îî‚îÄ‚îÄ components/       # Componentes reutilizables
‚îú‚îÄ‚îÄ üìÇ notebooks/         # An√°lisis exploratorio
‚îú‚îÄ‚îÄ üìÇ tests/             # Pruebas unitarias
‚îú‚îÄ‚îÄ üìÇ docker/            # Configuraci√≥n Docker
‚îú‚îÄ‚îÄ üìÑ requirements.txt   # Dependencias Python
‚îú‚îÄ‚îÄ üìÑ docker-compose.yml # Orquestaci√≥n de servicios
‚îî‚îÄ‚îÄ üìÑ README.md          # Este archivo
```

---

## üìä Fuentes de Datos

El proyecto integra **tres datasets oficiales** de Datos Abiertos Colombia:

### 1. üî¥ Dataset de Homicidios

**Prop√≥sito**: Datos hist√≥ricos de homicidios en Colombia

**Informaci√≥n incluida**:
- Fecha del homicidio
- Ubicaci√≥n (departamento, municipio, zona)
- Tipo de arma
- Circunstancias
- Datos demogr√°ficos de la v√≠ctima

**Uso en el proyecto**: Dataset principal para entrenamiento de modelos predictivos

### 2. üó∫Ô∏è DIVIPOLA Departamentos

**Prop√≥sito**: Divisi√≥n Pol√≠tico-Administrativa oficial de Colombia (DANE)

**Informaci√≥n incluida**:
- C√≥digo DANE del departamento (2 d√≠gitos)
- Nombre oficial del departamento
- Regi√≥n geogr√°fica
- Capital del departamento

**Uso en el proyecto**: 
- Estandarizaci√≥n de nombres de departamentos
- Joins precisos con datos de homicidios
- Agregaciones por regi√≥n
- Visualizaciones geogr√°ficas

### 3. üèòÔ∏è DIVIPOLA Municipios

**Prop√≥sito**: Cat√°logo oficial de municipios de Colombia (DANE)

**Informaci√≥n incluida**:
- C√≥digo DANE del municipio (5 d√≠gitos)
- Nombre oficial del municipio
- C√≥digo del departamento al que pertenece
- Categor√≠a del municipio (especial, 1, 2, 3, 4, 5, 6)
- Tipo (urbano, rural)
- Poblaci√≥n estimada

**Uso en el proyecto**:
- Estandarizaci√≥n de nombres de municipios
- Clasificaci√≥n por tipo y categor√≠a de municipio
- Features adicionales (poblaci√≥n, categor√≠a)
- Predicciones granulares a nivel municipal

### üîó Integraci√≥n de Datasets

```mermaid
graph LR
    A[Homicidios] -->|JOIN por c√≥digo DANE| B[DIVIPOLA Municipios]
    B -->|JOIN por c√≥digo depto| C[DIVIPOLA Departamentos]
    C --> D[Dataset Enriquecido]
    D --> E[Feature Engineering]
    E --> F[Modelos ML]
```

**Beneficios de usar DIVIPOLA**:
- ‚úÖ **C√≥digos √∫nicos**: Evita ambig√ºedades en nombres
- ‚úÖ **Datos oficiales**: Informaci√≥n validada por el DANE
- ‚úÖ **Features adicionales**: Poblaci√≥n, categor√≠a, tipo de municipio
- ‚úÖ **Joins precisos**: Relaciones uno-a-uno garantizadas

---

## üóÑÔ∏è Data Lake y Data Warehouse

### Data Lake - Almacenamiento Crudo

**Prop√≥sito**: Almacenar datos crudos con transformaciones m√≠nimas

**Ubicaci√≥n**: `./data/raw/`

**Formato**: Parquet (columnar, eficiente)

**Contenido**:
- Datos de homicidios con ID √∫nico asignado
- DIVIPOLA departamentos (carga √∫nica)
- DIVIPOLA municipios (carga √∫nica)

**Transformaciones**:
- ‚úÖ Asignaci√≥n de ID √∫nico (`homicidio_id`)
- ‚úÖ Conversi√≥n a Parquet
- ‚ùå Sin limpieza de datos
- ‚ùå Sin joins o agregaciones

### Data Warehouse - Modelo Estrella

**Prop√≥sito**: Datos procesados y optimizados para an√°lisis

**Ubicaci√≥n**: `./data/processed/`

**Modelo**: Star Schema (Estrella)

**Tablas**:

#### Tabla de Hechos
- `fact_homicidios`: Eventos de homicidios con m√©tricas

#### Dimensiones
- `dim_fecha`: Dimensi√≥n temporal (a√±o, mes, d√≠a, etc.)
- `dim_ubicacion`: Geograf√≠a enriquecida con DIVIPOLA
- `dim_victima`: Caracter√≠sticas demogr√°ficas
- `dim_arma`: Tipo de arma utilizada

**Documentaci√≥n completa**: Ver [docs/star_schema.md](docs/star_schema.md)

### Pipeline ETL

```mermaid
sequenceDiagram
    participant API as API Datos Abiertos
    participant Lake as Data Lake
    participant ETL as Proceso ETL
    participant DW as Data Warehouse
    participant ML as Modelos ML
    
    Note over API,Lake: Carga Inicial (Una vez)
    API->>Lake: Full load de homicidios
    API->>Lake: DIVIPOLA departamentos
    API->>Lake: DIVIPOLA municipios
    
    Note over API,Lake: Carga Incremental (Viernes)
    API->>Lake: Solo registros nuevos
    
    Note over Lake,DW: ETL Diario
    Lake->>ETL: Leer datos crudos
    ETL->>ETL: JOIN con DIVIPOLA
    ETL->>ETL: Crear dimensiones
    ETL->>DW: Cargar modelo estrella
    
    Note over DW,ML: An√°lisis y ML
    DW->>ML: Features para modelos
    ML->>ML: Entrenamiento
```

---

## üöÄ Instalaci√≥n y Configuraci√≥n

### Prerrequisitos

- Python 3.11 o superior
- Docker & Docker Compose (opcional, para containerizaci√≥n)
- Git

### 1. Clonar el Repositorio

```bash
git clone https://github.com/tu-usuario/ML-Homicidios.git
cd ML-Homicidios
```

### 2. Configurar Entorno Virtual

```bash
# Crear entorno virtual
python -m venv venv

# Activar entorno virtual
# Windows (Git Bash)
source venv/Scripts/activate

# Linux/Mac
source venv/bin/activate
```

### 3. Instalar Dependencias

```bash
pip install -r requirements.txt
```

### 4. Configurar Variables de Entorno

```bash
# Copiar template de variables de entorno
cp .env.example .env

# Editar .env con tus credenciales
nano .env
```

**Variables requeridas en `.env`:**
```env
# ============================================================================
# Datasets de Datos Abiertos Colombia
# ============================================================================

# 1. Dataset de Homicidios
DATOS_ABIERTOS_HOMICIDIOS_ID=tu_dataset_id_homicidios

# 2. DIVIPOLA Departamentos
DATOS_ABIERTOS_DIVIPOLA_DEPARTAMENTOS_ID=tu_dataset_id_departamentos

# 3. DIVIPOLA Municipios
DATOS_ABIERTOS_DIVIPOLA_MUNICIPIOS_ID=tu_dataset_id_municipios

# API Key (OPCIONAL - dejar vac√≠o para API p√∫blica)
DATOS_ABIERTOS_API_KEY=

# ============================================================================
# Base de Datos (SQLite por defecto para desarrollo)
# ============================================================================
DB_TYPE=sqlite
DB_PATH=./data/homicidios.db

# ============================================================================
# Configuraci√≥n de Modelos
# ============================================================================
DEFAULT_MODEL=xgboost
MODEL_N_ESTIMATORS=100
MODEL_MAX_DEPTH=6
MODEL_LEARNING_RATE=0.1

# ============================================================================
# Logging
# ============================================================================
LOG_LEVEL=INFO
LOG_FILE=./logs/ml_homicidios.log

# ============================================================================
# Ambiente
# ============================================================================
ENVIRONMENT=development
DEBUG=True
```

**üìù Nota**: Para encontrar los IDs de los datasets:
1. Ve a https://www.datos.gov.co
2. Busca cada dataset (homicidios, divipola departamentos, divipola municipios)
3. El ID est√° en la URL o en la secci√≥n "API" del dataset
4. Ejemplo de ID: `abcd-1234`

---

## üìä Uso

### Opci√≥n 1: Ejecuci√≥n Local

#### Extraer Datos

```bash
# Ejecutar extracci√≥n manual de datos
python -m src.data_ingestion.api_client
```

#### Ejecutar Pipeline ETL

```bash
# Procesar datos crudos
python -m src.etl.extract
python -m src.etl.transform
python -m src.etl.load
```

#### Entrenar Modelos

```bash
# Entrenar todos los modelos
python -m src.models.train

# Evaluar modelos
python -m src.models.evaluate
```

#### Lanzar Dashboard

```bash
# Iniciar aplicaci√≥n Streamlit
streamlit run app/streamlit_app.py
```

### Opci√≥n 2: Docker Compose

```bash
# Construir y levantar todos los servicios
docker-compose up --build

# Ejecutar en background
docker-compose up -d

# Ver logs
docker-compose logs -f

# Detener servicios
docker-compose down
```

---

## üß™ Testing

```bash
# Ejecutar todos los tests
pytest tests/ -v

# Con cobertura
pytest tests/ --cov=src --cov-report=html

# Tests espec√≠ficos
pytest tests/test_etl.py -v
```

---

## üìà Pipeline de Datos

### 1. Extracci√≥n (Extract)
- Conexi√≥n a API de Datos Abiertos
- Descarga de datos de homicidios
- Almacenamiento en Data Lake (Parquet)

### 2. Transformaci√≥n (Transform)
- Limpieza de datos
- Estandarizaci√≥n de ubicaciones
- Agregaciones por nivel geogr√°fico
- Generaci√≥n de features temporales

### 3. Carga (Load)
- Almacenamiento en Data Warehouse
- Versionado de datos
- Validaci√≥n de calidad

### 4. Automatizaci√≥n
- Cron job diario para extracci√≥n
- Reentrenamiento semanal de modelos
- Actualizaci√≥n autom√°tica de predicciones

---

## ü§ñ Modelos de Machine Learning

### Modelos Implementados

1. **Modelo por Departamento**
   - Predicci√≥n de tasas a nivel departamental
   - Features: hist√≥ricos, estacionalidad, tendencias

2. **Modelo por Municipio**
   - Predicci√≥n granular por municipio
   - Features: poblaci√≥n, tipo, departamento

3. **Modelo por Zona**
   - Predicci√≥n por zona geogr√°fica
   - Features: urbano/rural, caracter√≠sticas socioecon√≥micas

4. **Modelo por Tipo de Municipio**
   - Clasificaci√≥n y predicci√≥n por tipo
   - Features: categorizaci√≥n, patrones hist√≥ricos

### Algoritmos Utilizados
- **XGBoost**: Gradient boosting optimizado
- **LightGBM**: Alternativa r√°pida y eficiente
- **Prophet**: Series temporales
- **Scikit-learn**: Baseline y preprocessing

### M√©tricas de Evaluaci√≥n
- **RMSE** (Root Mean Square Error)
- **MAE** (Mean Absolute Error)
- **R¬≤** (Coefficient of Determination)
- **MAPE** (Mean Absolute Percentage Error)

---

## üì± Dashboard Streamlit

### P√°ginas Disponibles

#### üè† Home
- Resumen ejecutivo
- Estad√≠sticas clave
- Mapa interactivo de Colombia

#### üìä An√°lisis Exploratorio (EDA)
- Distribuciones de homicidios
- Tendencias temporales
- An√°lisis por regi√≥n

#### ü§ñ Predicciones
- Interfaz de predicci√≥n interactiva
- Selecci√≥n de ubicaci√≥n y horizonte
- Intervalos de confianza
- Visualizaci√≥n de resultados

#### üìà Tendencias
- An√°lisis hist√≥rico
- Patrones estacionales
- Comparativas regionales

---

## üîß Comandos √ötiles (Makefile)

```bash
# Setup inicial
make setup

# Ejecutar pipeline completo
make pipeline

# Entrenar modelos
make train

# Ejecutar tests
make test

# Limpiar archivos temporales
make clean

# Formatear c√≥digo
make format

# Linting
make lint
```

---

## üìù Roadmap

### Fase 1: Fundaci√≥n ‚úÖ
- [x] Estructura del proyecto
- [x] Configuraci√≥n de dependencias
- [x] README y documentaci√≥n

### Fase 2: Pipeline de Datos üöß
- [ ] Cliente API Datos Abiertos
- [ ] Pipeline ETL
- [ ] Data Lake y Warehouse
- [ ] Cron jobs

### Fase 3: Machine Learning üìÖ
- [ ] EDA y an√°lisis
- [ ] Feature engineering
- [ ] Entrenamiento de modelos
- [ ] Evaluaci√≥n y selecci√≥n

### Fase 4: Dashboard üìÖ
- [ ] Aplicaci√≥n Streamlit
- [ ] Visualizaciones
- [ ] Interfaz de predicciones

### Fase 5: Deployment üìÖ
- [ ] Docker containers
- [ ] Streamlit Cloud
- [ ] CI/CD
- [ ] Documentaci√≥n final

---

## ü§ù Contribuci√≥n

Este es un proyecto de aprendizaje. Si tienes sugerencias o mejoras:

1. Fork el proyecto
2. Crea una rama (`git checkout -b feature/mejora`)
3. Commit tus cambios (`git commit -m 'Agregar mejora'`)
4. Push a la rama (`git push origin feature/mejora`)
5. Abre un Pull Request

---

## üìö Recursos y Referencias

### Datos
- [Datos Abiertos Colombia](https://www.datos.gov.co/)
- [API Socrata](https://dev.socrata.com/)

### Documentaci√≥n
- [Streamlit Docs](https://docs.streamlit.io/)
- [Scikit-learn](https://scikit-learn.org/)
- [XGBoost](https://xgboost.readthedocs.io/)
- [Prophet](https://facebook.github.io/prophet/)

### Tutoriales
- [Docker para Data Science](https://docker-curriculum.com/)
- [MLOps Best Practices](https://ml-ops.org/)

---

## üìÑ Licencia

Este proyecto est√° bajo la Licencia MIT. Ver archivo `LICENSE` para m√°s detalles.

---

## üë§ Autor

**Rai De Le√≥n**

- GitHub: [@tu-usuario](https://github.com/tu-usuario)
- LinkedIn: [Tu Perfil](https://linkedin.com/in/tu-perfil)

---

## üôè Agradecimientos

- Datos Abiertos Colombia por proporcionar acceso a datos p√∫blicos
- Comunidad de Python y ML por las herramientas open source
- Streamlit por facilitar la creaci√≥n de dashboards

---

## üìû Contacto

¬øPreguntas o sugerencias? Abre un [issue](https://github.com/tu-usuario/ML-Homicidios/issues) o cont√°ctame directamente.

---

**‚≠ê Si este proyecto te resulta √∫til, considera darle una estrella en GitHub!**
