# ğŸ“š Manual Completo - Proyecto ML-Homicidios

## ğŸ¯ DescripciÃ³n del Proyecto

Sistema completo de anÃ¡lisis y predicciÃ³n de homicidios en Colombia, implementando una arquitectura de datos moderna con Data Lake, Data Warehouse (modelo estrella), y pipelines ETL automatizados.

---

## ğŸ“– Ãndice de DocumentaciÃ³n

### **ğŸ—„ï¸ Data Lake**

| Documento | DescripciÃ³n |
|-----------|-------------|
| [DL_ETL_Quickstart.md](DL_ETL_Quickstart.md) | GuÃ­a rÃ¡pida para ejecutar el ETL del Data Lake |
| [DL_Cron_Usage.md](DL_Cron_Usage.md) | Uso del servicio ETL con cron automÃ¡tico |
| [DL_Cron_Checklist.md](DL_Cron_Checklist.md) | Checklist de implementaciÃ³n y verificaciÃ³n |
| [DL_Loading_Strategy.md](DL_Loading_Strategy.md) | Estrategia de carga inicial e incremental |
| [DL_Migracion_Integer.md](DL_Migracion_Integer.md) | MigraciÃ³n de cÃ³digos DIVIPOLA a INTEGER |

### **ğŸ¢ Data Warehouse**

| Documento | DescripciÃ³n |
|-----------|-------------|
| [DWH_Modelo_Estrella.md](DWH_Modelo_Estrella.md) | Diagrama ER del modelo estrella |
| [DWH_Schema_Design.md](DWH_Schema_Design.md) | DiseÃ±o detallado del schema |
| [DWH_ETL_Quickstart.md](DWH_ETL_Quickstart.md) | GuÃ­a rÃ¡pida del ETL DWH |

### **ğŸ³ Docker & Infraestructura**

| Documento | UbicaciÃ³n | DescripciÃ³n |
|-----------|-----------|-------------|
| [QUICKSTART.md](../docker/QUICKSTART.md) | `docker/` | Inicio rÃ¡pido con Docker |
| [ADMINER_GUIDE.md](../docker/ADMINER_GUIDE.md) | `docker/` | GuÃ­a de uso de Adminer |
| [NETWORK_ACCESS.md](../docker/NETWORK_ACCESS.md) | `docker/` | ConfiguraciÃ³n de red |

---

## ğŸ—ï¸ Arquitectura del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FUENTE DE DATOS                          â”‚
â”‚              API Datos Abiertos Colombia                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â”‚ ETL Semanal (Viernes 23:00)
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     DATA LAKE                               â”‚
â”‚              PostgreSQL - Datos Raw                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ raw_homicidios                                     â”‚    â”‚
â”‚  â”‚ raw_divipola_departamentos                         â”‚    â”‚
â”‚  â”‚ raw_divipola_municipios                            â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â”‚ ETL TransformaciÃ³n (SÃ¡bado 01:00)
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  DATA WAREHOUSE                             â”‚
â”‚           PostgreSQL - Modelo Estrella                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Dimensiones:                                       â”‚    â”‚
â”‚  â”‚  - dim_fecha (8,340 registros)                     â”‚    â”‚
â”‚  â”‚  - dim_departamento (33 registros)                 â”‚    â”‚
â”‚  â”‚  - dim_municipio (1,121 registros)                 â”‚    â”‚
â”‚  â”‚  - dim_sexo (6 registros)                          â”‚    â”‚
â”‚  â”‚                                                     â”‚    â”‚
â”‚  â”‚ Hechos:                                            â”‚    â”‚
â”‚  â”‚  - fact_homicidios (332,131 registros)             â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â”‚ AnÃ¡lisis & ML
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              CAPA DE ANÃLISIS (Futuro)                      â”‚
â”‚  - Dashboards (Streamlit/PowerBI)                          â”‚
â”‚  - Modelos ML (XGBoost, LightGBM)                          â”‚
â”‚  - APIs de PredicciÃ³n                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Inicio RÃ¡pido

### **1. Levantar Infraestructura**

```bash
# Clonar repositorio
git clone <repo-url>
cd ML-Homicidios

# Configurar variables de entorno
cp .env.example .env
# Editar .env con tus credenciales de API

# Levantar servicios Docker
docker-compose up -d

# Verificar que todo estÃ© corriendo
docker ps
```

### **2. Carga Inicial de Datos**

```bash
# Data Lake - Carga inicial
docker exec ml-homicidios-etl-cron python scripts/load_datalake.py --initial

# Data Warehouse - Carga inicial
docker exec ml-homicidios-etl-cron python scripts/load_datawarehouse.py --initial
```

### **3. Verificar Datos**

```bash
# Acceder a Adminer
# URL: http://localhost:8080

# Data Lake
# Servidor: datalake | Usuario: datalake_user | Password: datalake_password_2024

# Data Warehouse
# Servidor: datawarehouse | Usuario: dw_user | Password: dw_password_2024
```

---

## ğŸ“Š Datos Disponibles

### **Data Lake (Raw)**
- **Homicidios**: ~332,000 registros (2003-2025)
- **Departamentos**: 33 departamentos
- **Municipios**: 1,121 municipios

### **Data Warehouse (Transformado)**
- **DimensiÃ³n Temporal**: 8,340 fechas
- **DimensiÃ³n GeogrÃ¡fica**: 33 departamentos + 1,121 municipios
- **DimensiÃ³n DemogrÃ¡fica**: 6 categorÃ­as de sexo
- **Tabla de Hechos**: 332,131 homicidios

---

## ğŸ¤– AutomatizaciÃ³n

### **Cron Jobs Configurados**

| Proceso | Frecuencia | Hora | Log |
|---------|------------|------|-----|
| Carga Data Lake | Viernes | 23:00 | `/app/logs/cron.log` |
| Carga Data Warehouse | SÃ¡bado | 01:00 | `/app/logs/cron_dwh.log` |
| Catch-up Data Lake | Diario | 08:00 | `/app/logs/catchup.log` |
| Catch-up DWH | Diario | 09:00 | `/app/logs/catchup_dwh.log` |
| Health Check | Diario | 02:00 | `/app/logs/health.log` |

### **Monitoreo**

```bash
# Ver logs en tiempo real
docker exec ml-homicidios-etl-cron tail -f /app/logs/cron.log
docker exec ml-homicidios-etl-cron tail -f /app/logs/cron_dwh.log

# Ver estado de contenedores
docker ps

# Ver logs de contenedor especÃ­fico
docker logs ml-homicidios-etl-cron --tail 50
```

---

## ğŸ”§ Comandos Ãštiles

### **Data Lake**

```bash
# Carga inicial
docker exec ml-homicidios-etl-cron python scripts/load_datalake.py --initial

# Carga incremental
docker exec ml-homicidios-etl-cron python scripts/load_datalake.py --incremental

# Verificar catch-up
docker exec ml-homicidios-etl-cron python scripts/catchup_check.py

# Health check
docker exec ml-homicidios-etl-cron python scripts/health_check.py
```

### **Data Warehouse**

```bash
# Carga inicial
docker exec ml-homicidios-etl-cron python scripts/load_datawarehouse.py --initial

# Carga incremental
docker exec ml-homicidios-etl-cron python scripts/load_datawarehouse.py --incremental

# Verificar catch-up
docker exec ml-homicidios-etl-cron python scripts/catchup_check_dwh.py
```

### **Base de Datos**

```bash
# Conectar a Data Lake
docker exec -it ml-homicidios-datalake psql -U datalake_user -d homicidios_datalake

# Conectar a Data Warehouse
docker exec -it ml-homicidios-datawarehouse psql -U dw_user -d homicidios_dw

# Contar registros
docker exec ml-homicidios-datalake psql -U datalake_user -d homicidios_datalake -c "SELECT COUNT(*) FROM raw_homicidios;"
docker exec ml-homicidios-datawarehouse psql -U dw_user -d homicidios_dw -c "SELECT COUNT(*) FROM fact_homicidios;"
```

---

## ğŸ“ˆ Vistas AnalÃ­ticas (DWH)

El Data Warehouse incluye vistas pre-calculadas para anÃ¡lisis:

```sql
-- Homicidios por departamento
SELECT * FROM v_homicidios_por_departamento LIMIT 10;

-- Homicidios por municipio
SELECT * FROM v_homicidios_por_municipio LIMIT 10;

-- Homicidios por sexo
SELECT * FROM v_homicidios_por_sexo;

-- Homicidios por mes
SELECT * FROM v_homicidios_por_mes ORDER BY aÃ±o DESC, mes DESC LIMIT 12;
```

---

## ğŸ› ï¸ Mantenimiento

### **Reiniciar Servicios**

```bash
# Reiniciar todos los servicios
docker-compose restart

# Reiniciar servicio especÃ­fico
docker-compose restart etl-cron
docker-compose restart datalake
docker-compose restart datawarehouse
```

### **Limpiar y Recrear**

```bash
# Detener servicios
docker-compose down

# Eliminar volÃºmenes (CUIDADO: Borra todos los datos)
docker volume rm ml-homicidios-datalake-data
docker volume rm ml-homicidios-datawarehouse-data

# Recrear desde cero
docker-compose up -d

# Esperar a que estÃ©n healthy
docker ps

# Cargar datos nuevamente
docker exec ml-homicidios-etl-cron python scripts/load_datalake.py --initial
docker exec ml-homicidios-etl-cron python scripts/load_datawarehouse.py --initial
```

---

## ğŸ“ Estructura del Proyecto

```
ML-Homicidios/
â”œâ”€â”€ docker/                      # ConfiguraciÃ³n Docker
â”‚   â”œâ”€â”€ Dockerfile.etl          # Imagen del servicio ETL
â”‚   â”œâ”€â”€ entrypoint-cron.sh      # Script de inicio
â”‚   â”œâ”€â”€ crontab                 # Cron jobs
â”‚   â””â”€â”€ init-scripts/           # Scripts de inicializaciÃ³n DB
â”‚       â”œâ”€â”€ 01-create-datalake-schema.sql
â”‚       â””â”€â”€ 02-create-datawarehouse-schema.sql
â”œâ”€â”€ src/                        # CÃ³digo fuente
â”‚   â”œâ”€â”€ config/                 # ConfiguraciÃ³n
â”‚   â”œâ”€â”€ data_ingestion/         # ETL Data Lake
â”‚   â””â”€â”€ data_warehouse/         # ETL Data Warehouse
â”œâ”€â”€ scripts/                    # Scripts de ejecuciÃ³n
â”‚   â”œâ”€â”€ load_datalake.py
â”‚   â”œâ”€â”€ load_datawarehouse.py
â”‚   â”œâ”€â”€ catchup_check.py
â”‚   â”œâ”€â”€ catchup_check_dwh.py
â”‚   â””â”€â”€ health_check.py
â”œâ”€â”€ docs/                       # DocumentaciÃ³n
â”‚   â”œâ”€â”€ README.md              # Este archivo
â”‚   â”œâ”€â”€ DL_*.md                # Docs Data Lake
â”‚   â””â”€â”€ DWH_*.md               # Docs Data Warehouse
â”œâ”€â”€ docker-compose.yml          # OrquestaciÃ³n de servicios
â”œâ”€â”€ .env.example               # Template de variables
â””â”€â”€ requirements.txt           # Dependencias Python
```

---

## ğŸ” Seguridad

- âœ… Credenciales en `.env` (nunca en Git)
- âœ… `.env` en `.gitignore`
- âœ… ContraseÃ±as fuertes por defecto
- âœ… Red Docker aislada
- âœ… Puertos expuestos solo los necesarios

---

## ğŸ› Troubleshooting

### **Contenedor ETL reiniciando**

```bash
# Ver logs
docker logs ml-homicidios-etl-cron --tail 100

# Verificar conexiones
docker exec ml-homicidios-etl-cron python -c "from src.data_ingestion.db_connection import DatabaseConnection; db = DatabaseConnection(); print('OK' if db.test_connection() else 'FAIL')"
```

### **No hay datos en DWH**

```bash
# Verificar Data Lake
docker exec ml-homicidios-datalake psql -U datalake_user -d homicidios_datalake -c "SELECT COUNT(*) FROM raw_homicidios;"

# Ejecutar carga inicial DWH
docker exec ml-homicidios-etl-cron python scripts/load_datawarehouse.py --initial
```

### **Cron jobs no ejecutan**

```bash
# Verificar crontab
docker exec ml-homicidios-etl-cron crontab -l

# Ver logs de cron
docker exec ml-homicidios-etl-cron tail -f /app/logs/cron.log
```

---

## ğŸ“ Soporte

Para mÃ¡s informaciÃ³n, consulta la documentaciÃ³n especÃ­fica en la carpeta `docs/`:
- **Data Lake**: Archivos con prefijo `DL_`
- **Data Warehouse**: Archivos con prefijo `DWH_`
- **Docker**: Carpeta `docker/`

---

## âœ… Checklist de ImplementaciÃ³n

- [x] Docker Compose configurado
- [x] Data Lake schema creado
- [x] Data Warehouse schema creado
- [x] ETL Data Lake implementado
- [x] ETL Data Warehouse implementado
- [x] Cron jobs configurados
- [x] Catch-up automÃ¡tico implementado
- [x] Health checks configurados
- [x] DocumentaciÃ³n completa
- [x] Vistas analÃ­ticas creadas

---

Â¡El sistema estÃ¡ listo para anÃ¡lisis y Machine Learning! ğŸš€
