# ğŸ” ML-Homicidios

**Sistema de Machine Learning para PredicciÃ³n de Tasas de Homicidios en Colombia**

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-red.svg)](https://streamlit.io/)
[![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)](https://www.docker.com/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

---

## ğŸ“‹ DescripciÃ³n

ML-Homicidios es un sistema completo de Machine Learning containerizado que predice tasas de homicidios en Colombia a nivel de:
- ğŸ›ï¸ **Departamento**
- ğŸ™ï¸ **Municipio**
- ğŸ“ **Zona**
- ğŸ˜ï¸ **Tipo de Municipio**

El sistema extrae automÃ¡ticamente datos de la **API de Datos Abiertos de Colombia**, los procesa a travÃ©s de un pipeline ETL hacia un Data Lake y Data Warehouse, entrena modelos de ML, y sirve predicciones a travÃ©s de un dashboard interactivo de Streamlit.

---

## ğŸ¯ Objetivos del Proyecto

1. **Aprendizaje**: Desarrollar habilidades en ingenierÃ­a de datos y ML en producciÃ³n
2. **PredicciÃ³n**: Generar predicciones precisas de tasas de homicidios
3. **VisualizaciÃ³n**: Proporcionar insights accionables a travÃ©s de dashboards interactivos
4. **AutomatizaciÃ³n**: Pipeline completamente automatizado con cron jobs

---

## ğŸ—ï¸ Arquitectura

```mermaid
graph TB
    subgraph "Capa de Ingesta"
        A[API Datos Abiertos] -->|Cron Diario| B[Extractor de Datos]
        B --> C[Data Lake - Raw]
    end
    
    subgraph "Capa de Procesamiento"
        C --> D[Pipeline ETL]
        D --> E[Data Warehouse]
    end
    
    subgraph "Capa de ML"
        E --> F[Feature Engineering]
        F --> G[Entrenamiento]
        G --> H[Modelos Entrenados]
    end
    
    subgraph "Capa de AplicaciÃ³n"
        H --> I[Dashboard Streamlit]
        E --> I
        I --> J[Streamlit Cloud]
    end
    
    style A fill:#e1f5ff
    style J fill:#ffe1f5
```

---

## ğŸ› ï¸ Stack TecnolÃ³gico

### Core
- **Python 3.11+**: Lenguaje principal
- **Docker & Docker Compose**: ContainerizaciÃ³n
- **Git**: Control de versiones

### Data Pipeline
- **Requests & Sodapy**: ExtracciÃ³n de datos de APIs
- **Pandas & Polars**: ManipulaciÃ³n de datos
- **Parquet**: Almacenamiento eficiente (Data Lake)
- **Python-Crontab**: AutomatizaciÃ³n de tareas

### Machine Learning
- **Scikit-learn**: Algoritmos base y preprocessing
- **XGBoost & LightGBM**: Gradient boosting
- **Prophet**: Forecasting de series temporales
- **MLflow**: Tracking de experimentos (opcional)

### VisualizaciÃ³n
- **Streamlit**: Framework de dashboard
- **Plotly**: GrÃ¡ficos interactivos
- **Folium & GeoPandas**: Mapas de Colombia

### Testing & Quality
- **Pytest**: Framework de testing
- **Black, Flake8, Isort**: Code quality
- **MyPy**: Type checking

---

## ğŸ“ Estructura del Proyecto

```
ML-Homicidios/
â”œâ”€â”€ ğŸ“‚ data/
â”‚   â”œâ”€â”€ raw/              # Data Lake - Datos crudos
â”‚   â”œâ”€â”€ processed/        # Data Warehouse - Datos procesados
â”‚   â””â”€â”€ models/           # Modelos entrenados
â”œâ”€â”€ ğŸ“‚ src/
â”‚   â”œâ”€â”€ config/           # ConfiguraciÃ³n centralizada
â”‚   â”œâ”€â”€ data_ingestion/   # Cliente API y scheduler
â”‚   â”œâ”€â”€ etl/              # Pipeline ETL
â”‚   â”œâ”€â”€ features/         # IngenierÃ­a de features
â”‚   â”œâ”€â”€ models/           # Entrenamiento y predicciÃ³n
â”‚   â””â”€â”€ utils/            # Utilidades y logging
â”œâ”€â”€ ğŸ“‚ app/
â”‚   â”œâ”€â”€ streamlit_app.py  # Dashboard principal
â”‚   â”œâ”€â”€ pages/            # PÃ¡ginas del dashboard
â”‚   â””â”€â”€ components/       # Componentes reutilizables
â”œâ”€â”€ ğŸ“‚ notebooks/         # AnÃ¡lisis exploratorio
â”œâ”€â”€ ğŸ“‚ tests/             # Pruebas unitarias
â”œâ”€â”€ ğŸ“‚ docker/            # ConfiguraciÃ³n Docker
â”œâ”€â”€ ğŸ“„ requirements.txt   # Dependencias Python
â”œâ”€â”€ ğŸ“„ docker-compose.yml # OrquestaciÃ³n de servicios
â””â”€â”€ ğŸ“„ README.md          # Este archivo
```

---

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### Prerrequisitos

- Python 3.11 o superior
- Docker & Docker Compose (opcional, para containerizaciÃ³n)
- Git

### 1. Clonar el Repositorio

```bash
git clone https://github.com/tu-usuario/ML-Homicidios.git
cd ML-Homicidios
```

### 2. Configurar Entorno Virtual

```bash
# Crear entorno virtual
python -m venv venv

# Activar entorno virtual
# Windows (Git Bash)
source venv/Scripts/activate

# Linux/Mac
source venv/bin/activate
```

### 3. Instalar Dependencias

```bash
pip install -r requirements.txt
```

### 4. Configurar Variables de Entorno

```bash
# Copiar template de variables de entorno
cp .env.example .env

# Editar .env con tus credenciales
nano .env
```

**Variables requeridas en `.env`:**
```env
# API Datos Abiertos
DATOS_ABIERTOS_API_KEY=tu_api_key_aqui
DATOS_ABIERTOS_DATASET_ID=dataset_id_aqui

# Database (opcional)
DB_HOST=localhost
DB_PORT=5432
DB_NAME=homicidios_db
DB_USER=usuario
DB_PASSWORD=contraseÃ±a

# Paths
DATA_RAW_PATH=./data/raw
DATA_PROCESSED_PATH=./data/processed
MODELS_PATH=./data/models

# Logging
LOG_LEVEL=INFO
```

---

## ğŸ“Š Uso

### OpciÃ³n 1: EjecuciÃ³n Local

#### Extraer Datos

```bash
# Ejecutar extracciÃ³n manual de datos
python -m src.data_ingestion.api_client
```

#### Ejecutar Pipeline ETL

```bash
# Procesar datos crudos
python -m src.etl.extract
python -m src.etl.transform
python -m src.etl.load
```

#### Entrenar Modelos

```bash
# Entrenar todos los modelos
python -m src.models.train

# Evaluar modelos
python -m src.models.evaluate
```

#### Lanzar Dashboard

```bash
# Iniciar aplicaciÃ³n Streamlit
streamlit run app/streamlit_app.py
```

### OpciÃ³n 2: Docker Compose

```bash
# Construir y levantar todos los servicios
docker-compose up --build

# Ejecutar en background
docker-compose up -d

# Ver logs
docker-compose logs -f

# Detener servicios
docker-compose down
```

---

## ğŸ§ª Testing

```bash
# Ejecutar todos los tests
pytest tests/ -v

# Con cobertura
pytest tests/ --cov=src --cov-report=html

# Tests especÃ­ficos
pytest tests/test_etl.py -v
```

---

## ğŸ“ˆ Pipeline de Datos

### 1. ExtracciÃ³n (Extract)
- ConexiÃ³n a API de Datos Abiertos
- Descarga de datos de homicidios
- Almacenamiento en Data Lake (Parquet)

### 2. TransformaciÃ³n (Transform)
- Limpieza de datos
- EstandarizaciÃ³n de ubicaciones
- Agregaciones por nivel geogrÃ¡fico
- GeneraciÃ³n de features temporales

### 3. Carga (Load)
- Almacenamiento en Data Warehouse
- Versionado de datos
- ValidaciÃ³n de calidad

### 4. AutomatizaciÃ³n
- Cron job diario para extracciÃ³n
- Reentrenamiento semanal de modelos
- ActualizaciÃ³n automÃ¡tica de predicciones

---

## ğŸ¤– Modelos de Machine Learning

### Modelos Implementados

1. **Modelo por Departamento**
   - PredicciÃ³n de tasas a nivel departamental
   - Features: histÃ³ricos, estacionalidad, tendencias

2. **Modelo por Municipio**
   - PredicciÃ³n granular por municipio
   - Features: poblaciÃ³n, tipo, departamento

3. **Modelo por Zona**
   - PredicciÃ³n por zona geogrÃ¡fica
   - Features: urbano/rural, caracterÃ­sticas socioeconÃ³micas

4. **Modelo por Tipo de Municipio**
   - ClasificaciÃ³n y predicciÃ³n por tipo
   - Features: categorizaciÃ³n, patrones histÃ³ricos

### Algoritmos Utilizados
- **XGBoost**: Gradient boosting optimizado
- **LightGBM**: Alternativa rÃ¡pida y eficiente
- **Prophet**: Series temporales
- **Scikit-learn**: Baseline y preprocessing

### MÃ©tricas de EvaluaciÃ³n
- **RMSE** (Root Mean Square Error)
- **MAE** (Mean Absolute Error)
- **RÂ²** (Coefficient of Determination)
- **MAPE** (Mean Absolute Percentage Error)

---

## ğŸ“± Dashboard Streamlit

### PÃ¡ginas Disponibles

#### ğŸ  Home
- Resumen ejecutivo
- EstadÃ­sticas clave
- Mapa interactivo de Colombia

#### ğŸ“Š AnÃ¡lisis Exploratorio (EDA)
- Distribuciones de homicidios
- Tendencias temporales
- AnÃ¡lisis por regiÃ³n

#### ğŸ¤– Predicciones
- Interfaz de predicciÃ³n interactiva
- SelecciÃ³n de ubicaciÃ³n y horizonte
- Intervalos de confianza
- VisualizaciÃ³n de resultados

#### ğŸ“ˆ Tendencias
- AnÃ¡lisis histÃ³rico
- Patrones estacionales
- Comparativas regionales

---

## ğŸ”§ Comandos Ãštiles (Makefile)

```bash
# Setup inicial
make setup

# Ejecutar pipeline completo
make pipeline

# Entrenar modelos
make train

# Ejecutar tests
make test

# Limpiar archivos temporales
make clean

# Formatear cÃ³digo
make format

# Linting
make lint
```

---

## ğŸ“ Roadmap

### Fase 1: FundaciÃ³n âœ…
- [x] Estructura del proyecto
- [x] ConfiguraciÃ³n de dependencias
- [x] README y documentaciÃ³n

### Fase 2: Pipeline de Datos ğŸš§
- [ ] Cliente API Datos Abiertos
- [ ] Pipeline ETL
- [ ] Data Lake y Warehouse
- [ ] Cron jobs

### Fase 3: Machine Learning ğŸ“…
- [ ] EDA y anÃ¡lisis
- [ ] Feature engineering
- [ ] Entrenamiento de modelos
- [ ] EvaluaciÃ³n y selecciÃ³n

### Fase 4: Dashboard ğŸ“…
- [ ] AplicaciÃ³n Streamlit
- [ ] Visualizaciones
- [ ] Interfaz de predicciones

### Fase 5: Deployment ğŸ“…
- [ ] Docker containers
- [ ] Streamlit Cloud
- [ ] CI/CD
- [ ] DocumentaciÃ³n final

---

## ğŸ¤ ContribuciÃ³n

Este es un proyecto de aprendizaje. Si tienes sugerencias o mejoras:

1. Fork el proyecto
2. Crea una rama (`git checkout -b feature/mejora`)
3. Commit tus cambios (`git commit -m 'Agregar mejora'`)
4. Push a la rama (`git push origin feature/mejora`)
5. Abre un Pull Request

---

## ğŸ“š Recursos y Referencias

### Datos
- [Datos Abiertos Colombia](https://www.datos.gov.co/)
- [API Socrata](https://dev.socrata.com/)

### DocumentaciÃ³n
- [Streamlit Docs](https://docs.streamlit.io/)
- [Scikit-learn](https://scikit-learn.org/)
- [XGBoost](https://xgboost.readthedocs.io/)
- [Prophet](https://facebook.github.io/prophet/)

### Tutoriales
- [Docker para Data Science](https://docker-curriculum.com/)
- [MLOps Best Practices](https://ml-ops.org/)

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver archivo `LICENSE` para mÃ¡s detalles.

---

## ğŸ‘¤ Autor

**Rai De LeÃ³n**

- GitHub: [@tu-usuario](https://github.com/tu-usuario)
- LinkedIn: [Tu Perfil](https://linkedin.com/in/tu-perfil)

---

## ğŸ™ Agradecimientos

- Datos Abiertos Colombia por proporcionar acceso a datos pÃºblicos
- Comunidad de Python y ML por las herramientas open source
- Streamlit por facilitar la creaciÃ³n de dashboards

---

## ğŸ“ Contacto

Â¿Preguntas o sugerencias? Abre un [issue](https://github.com/tu-usuario/ML-Homicidios/issues) o contÃ¡ctame directamente.

---

**â­ Si este proyecto te resulta Ãºtil, considera darle una estrella en GitHub!**
